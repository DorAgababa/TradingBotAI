{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "import polars as pl\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from enum import Enum\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn.preprocessing as preprocessing\n",
    "import keras\n",
    "from keras.models import Model\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, LSTM, Input, Activation, concatenate, Input,  TimeDistributed, concatenate\n",
    "from keras import optimizers\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "from keras.utils import plot_model\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "columns_to_normalize = [\"close\", \"ema5\", \"ema20\" , \"macd520\"]\n",
    "\n",
    "def read_data(train_file = 'train_data.csv', val_file = 'val_data.csv', test_file = 'test_data.csv'):\n",
    "    train_data = pl.read_csv(train_file)\n",
    "    val_data = pl.read_csv(val_file)\n",
    "    test_data = pl.read_csv(test_file)\n",
    "    return train_data, val_data, test_data\n",
    "\n",
    "#get data of x and y and return x and y, slice y\n",
    "def extract_y(data):\n",
    "    y = data['next_5_min']\n",
    "    x = data.drop('next_5_min')\n",
    "    return x,y\n",
    "\n",
    "\n",
    "#we should not use min max scale cause the max changing over the time.\n",
    "#we need to deal with two kinds of things : 1. train data - we need to create a scaler and fit it to the train, and then create a normalized data , 2. test/validation data - we should get as input the scaler of the train, and do normalize by him\n",
    "def min_max_scaler(data):\n",
    "    scaler = preprocessing.MinMaxScaler()\n",
    "    scaled_data = scaler.fit_transform(data)\n",
    "    return scaled_data, scaler\n",
    "\n",
    "def z_score_normalize(data):\n",
    "    scaler = preprocessing.StandardScaler()\n",
    "    scaled_data = scaler.fit_transform(data)\n",
    "    return scaled_data, scaler\n",
    "    \n",
    "def scale_back(data, scaler):\n",
    "    return scaler.inverse_transform(data)\n",
    "\n",
    "def normalized_x_y(x: pl.DataFrame, y: pl.DataFrame, columns_to_normalize: list):\n",
    "    # Convert Polars DataFrame to NumPy array for normalization\n",
    "    x_values = x.select(columns_to_normalize).to_numpy()\n",
    "    y_values = y.to_numpy().reshape(-1, 1)\n",
    "    # Normalize\n",
    "    normalized_x_values, scaler_x = z_score_normalize(x_values)\n",
    "    normalized_y_values, scaler_y = z_score_normalize(y_values)\n",
    "    # Convert back to Polars DataFrame\n",
    "    normalized_x = pl.DataFrame(normalized_x_values, schema=columns_to_normalize)\n",
    "    normalized_y = pl.DataFrame(normalized_y_values, schema=['normalized_y'])\n",
    "\n",
    "    return normalized_x, normalized_y, scaler_x, scaler_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, val_data, test_data = read_data()\n",
    "x_train, y_train = extract_y(train_data)\n",
    "x_val, y_val = extract_y(val_data)\n",
    "x_test, y_test = extract_y(test_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape: (3, 4)\n",
      "┌───────────┬───────────┬───────────┬──────────┐\n",
      "│ close     ┆ ema5      ┆ ema20     ┆ macd520  │\n",
      "│ ---       ┆ ---       ┆ ---       ┆ ---      │\n",
      "│ f64       ┆ f64       ┆ f64       ┆ f64      │\n",
      "╞═══════════╪═══════════╪═══════════╪══════════╡\n",
      "│ -0.862746 ┆ -0.865432 ┆ -0.86851  ┆ 1.076178 │\n",
      "│ -0.858736 ┆ -0.860492 ┆ -0.865335 ┆ 1.698643 │\n",
      "│ -0.860193 ┆ -0.861329 ┆ -0.863936 ┆ 0.910139 │\n",
      "└───────────┴───────────┴───────────┴──────────┘\n",
      "shape: (3, 1)\n",
      "┌──────────────┐\n",
      "│ normalized_y │\n",
      "│ ---          │\n",
      "│ f64          │\n",
      "╞══════════════╡\n",
      "│ -0.863859    │\n",
      "│ -0.861666    │\n",
      "│ -0.857984    │\n",
      "└──────────────┘\n"
     ]
    }
   ],
   "source": [
    "# Split data to train val and test and normalize the data\n",
    "x_train, y_train, x_train_scaler, y_train_scaler = normalized_x_y(x_train, y_train, columns_to_normalize)\n",
    "x_test, y_test, x_test_scaler, y_test_scaler = normalized_x_y(x_val, y_val, columns_to_normalize)\n",
    "x_val, y_val, x_val_scaler, y_val_scaler = normalized_x_y(x_test, y_test, columns_to_normalize)\n",
    "print(x_test[:3])\n",
    "print(y_test[:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\David\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    }
   ],
   "source": [
    "history_points = 10\n",
    "model = Sequential()\n",
    "model.add(LSTM(50, input_shape=(history_points, 4)))\n",
    "model.add(Dropout(0.2))\n",
    "# Add Dense layer\n",
    "model.add(Dense(64, activation='sigmoid'))\n",
    "\n",
    "# Add output Dense layer\n",
    "model.add(Dense(1, activation='linear'))\n",
    "\n",
    "# Compile the model\n",
    "adam = optimizers.Adam(learning_rate=0.0005)\n",
    "model.compile(optimizer=adam, loss='mse')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m617/617\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step\n"
     ]
    }
   ],
   "source": [
    "def prepare_lstm_data(x, y, history_points):\n",
    "    x_sequences = create_sequences(x, history_points)\n",
    "    y_sequences = create_sequences(y, history_points)\n",
    "    return x_sequences, y_sequences\n",
    "\n",
    "def create_sequences(data, history_points):\n",
    "    sequences = []\n",
    "    for i in range(len(data) - history_points + 1):\n",
    "        sequences.append(data[i:i + history_points])\n",
    "    return np.array(sequences)\n",
    "\n",
    "x_train_prepared, y_train_prepared = prepare_lstm_data(x_train, y_train, history_points)\n",
    "x_val_prepared, y_val_prepared = prepare_lstm_data(x_val, y_val, history_points)\n",
    "# Train the model\n",
    "model.fit(x=x_train_prepared, y=y_train_prepared, batch_size=25, epochs=1, verbose=0)\n",
    "\n",
    "# Predict and evaluate\n",
    "y_val_predicted = model.predict(x_val_prepared)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_val_prepared: [[-0.86166607]\n",
      " [-0.85798417]\n",
      " [-0.85746052]\n",
      " [-0.85767325]\n",
      " [-0.85638049]\n",
      " [-0.85606958]\n",
      " [-0.85523501]\n",
      " [-0.8544659 ]\n",
      " [-0.85557866]\n",
      " [-0.85791871]]\n",
      "y_val_predicted: [-0.85995865]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "operands could not be broadcast together with shapes (19716,10,1) (19716,1) ",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[134], line 7\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my_val_predicted:\u001b[39m\u001b[38;5;124m\"\u001b[39m,y_val_predicted[\u001b[38;5;241m1\u001b[39m])\n\u001b[0;32m      6\u001b[0m \u001b[38;5;66;03m# Compute RMSE\u001b[39;00m\n\u001b[1;32m----> 7\u001b[0m rmse \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39msqrt(np\u001b[38;5;241m.\u001b[39mmean(np\u001b[38;5;241m.\u001b[39msquare(\u001b[43my_val_prepared\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43m \u001b[49m\u001b[43my_val_predicted\u001b[49m)))\n\u001b[0;32m      9\u001b[0m \u001b[38;5;66;03m# # Compute scaled RMSE\u001b[39;00m\n\u001b[0;32m     10\u001b[0m scaled_rmse \u001b[38;5;241m=\u001b[39m rmse \u001b[38;5;241m/\u001b[39m (np\u001b[38;5;241m.\u001b[39mmax(y_val_predicted) \u001b[38;5;241m-\u001b[39m np\u001b[38;5;241m.\u001b[39mmin(y_val_predicted)) \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m100\u001b[39m\n",
      "\u001b[1;31mValueError\u001b[0m: operands could not be broadcast together with shapes (19716,10,1) (19716,1) "
     ]
    }
   ],
   "source": [
    "#convert back to polars\n",
    "y_val_predicted_np = np.array(y_val_predicted).reshape(-1, 1)\n",
    "y_val_predicted_s = y_val_scaler.inverse_transform(y_val_predicted_np)\n",
    "print(\"x_val_prepared:\",y_val_prepared[1])\n",
    "print(\"y_val_predicted:\",y_val_predicted[1])\n",
    "# Compute RMSE\n",
    "rmse = np.sqrt(np.mean(np.square(y_val_prepared - y_val_predicted)))\n",
    "\n",
    "# # Compute scaled RMSE\n",
    "scaled_rmse = rmse / (np.max(y_val_predicted) - np.min(y_val_predicted)) * 100\n",
    "\n",
    "print(\"Adjusted Prediction Root Mean Squared Error for real data: {:.2f} %\".format(scaled_rmse))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You must install pydot (`pip install pydot`) for `plot_model` to work.\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'y_test_real' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[127], line 7\u001b[0m\n\u001b[0;32m      4\u001b[0m start \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m      5\u001b[0m end \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m\n\u001b[1;32m----> 7\u001b[0m real \u001b[38;5;241m=\u001b[39m plt\u001b[38;5;241m.\u001b[39mplot(\u001b[43my_test_real\u001b[49m[start:end], label\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mreal\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      8\u001b[0m pred \u001b[38;5;241m=\u001b[39m plt\u001b[38;5;241m.\u001b[39mplot(y_test_predicted[start:end], label\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpredicted\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     10\u001b[0m plt\u001b[38;5;241m.\u001b[39mlegend([\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mReal\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPredicted\u001b[39m\u001b[38;5;124m'\u001b[39m])\n",
      "\u001b[1;31mNameError\u001b[0m: name 'y_test_real' is not defined"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 2200x1500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_model(model, to_file='model.v1.png')\n",
    "plt.gcf().set_size_inches(22, 15, forward=True)\n",
    "\n",
    "start = 0\n",
    "end = -1\n",
    "\n",
    "real = plt.plot(y_test_real[start:end], label='real')\n",
    "pred = plt.plot(y_test_predicted[start:end], label='predicted')\n",
    "\n",
    "plt.legend(['Real', 'Predicted'])\n",
    "\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
